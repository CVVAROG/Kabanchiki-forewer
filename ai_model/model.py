import pandas as pd, joblib, torch
from topic_model_v43_patch import TopicModelV43, Config
import onnx

# –≤–∞—à —Ñ–∞–π–ª —Å –æ—Ç–∑—ã–≤–∞–º–∏, –æ–¥–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ text (UTF-8)
df = pd.read_csv("reviews.csv")
texts = df["text"].astype(str).tolist()

# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
mdl = TopicModelV43(Config(verbose=True))
mdl.fit(texts)
mdl.build_terms_and_names(texts)
mdl.calibrate_thresholds(texts[:min(3000, len(texts))])
mdl.build_gold_mapping_and_priors()

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –≤ pkl
joblib.dump(mdl.export_artifacts(), "v43_artifacts.pkl", compress=3)
print("‚úÖ –ê—Ä—Ç–µ—Ñ–∞–∫—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã ‚Üí v43_artifacts.pkl")

# üîπ –≠–∫—Å–ø–æ—Ä—Ç –≤ ONNX
import torch.onnx
import numpy as np

class Wrapper(torch.nn.Module):
    def __init__(self, mdl):
        super().__init__()
        self.mdl = mdl
    def forward(self, input_ids, attention_mask):
        # –∑–¥–µ—Å—å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ç–≤–æ–π –ø–∞–π–ø–ª–∞–π–Ω
        # –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞ –ø—Ä–æ—Å—Ç–æ –∏–º–∏—Ç–∞—Ü–∏—è logits
        logits = torch.randn((input_ids.shape[0], len(mdl.topics)))
        return logits

onnx_model = Wrapper(mdl)

# —Ñ–∏–∫—Ç–∏–≤–Ω—ã–π –≤—Ö–æ–¥ (–±–∞—Ç—á –∏–∑ 1, 16 —Ç–æ–∫–µ–Ω–æ–≤)
dummy_input_ids = torch.randint(0, 1000, (1,16))
dummy_attention_mask = torch.ones_like(dummy_input_ids)

torch.onnx.export(
    onnx_model,
    (dummy_input_ids, dummy_attention_mask),
    "v43_model.onnx",
    input_names=["input_ids", "attention_mask"],
    output_names=["logits"],
    dynamic_axes={
        "input_ids": {0: "batch", 1: "seq"},
        "attention_mask": {0: "batch", 1: "seq"},
        "logits": {0: "batch"}
    },
    opset_version=17
)
print("‚úÖ –≠–∫—Å–ø–æ—Ä—Ç –≤ ONNX –∑–∞–≤–µ—Ä—à—ë–Ω ‚Üí v43_model.onnx")
